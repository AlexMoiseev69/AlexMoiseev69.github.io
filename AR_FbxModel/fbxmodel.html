<!DOCTYPE html>
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
<!-- three.js library -->
<script src='Lib/utils/three.min.js'></script>
<!-- ar.js -->
<script src="Lib/ar/ar.js"></script>
<script src="Lib/loaders/FBXLoader.js"></script>
<script src="Lib/loaders/inflate.min.js"></script> <!-- FBX -->
<!-- <script>THREEx.ArToolkitContext.baseURL = '../../lib/ar'</script> -->

<body style='margin : 0px; overflow: hidden; font-family: Monospace;'>
<canvas></canvas>
<a href="#" id="download-photo" download="photo.png"></a>
<script>
	//////////////////////////////////////////////////////////////////////////////////
	//		Init
	//////////////////////////////////////////////////////////////////////////////////
	var orientation = 0;
	window.addEventListener("orientationchange", function() {
		if(screen.orientation.angle !== 90 || screen.orientation.angle !== 270){
			orientation = 0;
		}
		else{
			orientation = 1;
		}
   		// alert("the orientation of the device is now " + screen.orientation.angle);
	});
		
	// init renderer
	var renderer	= new THREE.WebGLRenderer({
		antialias: true,
		alpha: true,
		preserveDrawingBuffer: true
	});
	renderer.setClearColor(new THREE.Color('lightgrey'), 0)
	renderer.setSize( window.innerWidth, window.innerHeight );
	renderer.domElement.style.position = 'absolute'
	renderer.domElement.style.top = '0px'
	renderer.domElement.style.left = '0px'
	document.body.appendChild( renderer.domElement );

	// array of functions for the rendering loop
	var onRenderFcts= [];

	// init scene and camera
	var scene	= new THREE.Scene();

	light = new THREE.HemisphereLight(0xffffff, 0x444444, 1.0);
	light.position.set(0, 1, 0);
	scene.add(light);
	light = new THREE.DirectionalLight(0xffffff, 1.0);
	light.position.set(0, 1, 0);
	scene.add(light);
		
	//////////////////////////////////////////////////////////////////////////////////
	//		Initialize a basic camera
	//////////////////////////////////////////////////////////////////////////////////

	// Create a camera
	var camera = new THREE.Camera();
	scene.add(camera);

	////////////////////////////////////////////////////////////////////////////////
	//          handle arToolkitSource
	////////////////////////////////////////////////////////////////////////////////

	var arToolkitSource = new THREEx.ArToolkitSource({
		// to read from the webcam 
		sourceType : 'webcam',
		
		// // to read from an image
		// sourceType : 'image',
		// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/images/img.jpg',		

		// to read from a video
		// sourceType : 'video',
		// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/videos/headtracking.mp4',		
	})

	arToolkitSource.init(function onReady(){
		onResize()
	})
	
	// handle resize
	window.addEventListener('resize', function(){
		onResize()
	})
	function onResize(){
		// alert("resize!");
		// console.log(screen.orientation);
		arToolkitSource.onResize();	
		// arToolkitSource.copySizeTo(renderer.domElement);
		if(orientation===0)
		{
			renderer.domElement.style.width = arToolkitSource.domElement.style.width;
			renderer.domElement.style.height = arToolkitSource.domElement.style.height;
			renderer.domElement.style.marginLeft = arToolkitSource.domElement.style.marginLeft;
			renderer.domElement.style.marginTop = arToolkitSource.domElement.style.marginTop;
		}
		else{
			renderer.domElement.style.width = arToolkitSource.domElement.style.height;
			renderer.domElement.style.height = arToolkitSource.domElement.style.width;
			renderer.domElement.style.marginLeft = arToolkitSource.domElement.style.marginTop;
			renderer.domElement.style.marginTop = arToolkitSource.domElement.style.marginLeft;
		}
		if( arToolkitContext.arController !== null ){
			arToolkitSource.copySizeTo(arToolkitContext.arController.canvas);
		}	
	}
	////////////////////////////////////////////////////////////////////////////////
	//          initialize arToolkitContext
	////////////////////////////////////////////////////////////////////////////////
	

	// create atToolkitContext
	var arToolkitContext = new THREEx.ArToolkitContext({
		cameraParametersUrl: 'data/camera_para.dat',
		detectionMode: 'mono',
	})
	// initialize it
	arToolkitContext.init(function onCompleted(){
		// copy projection matrix to camera
		camera.projectionMatrix.copy( arToolkitContext.getProjectionMatrix() );
	})

	// update artoolkit on every frame
	onRenderFcts.push(function(){
		if( arToolkitSource.ready === false )	return

		arToolkitContext.update( arToolkitSource.domElement )
		
		// update scene.visible if the marker is seen
		scene.visible = camera.visible
	})
		
	////////////////////////////////////////////////////////////////////////////////
	//          Create a ArMarkerControls
	////////////////////////////////////////////////////////////////////////////////
	
	// init controls for camera
	var markerControls = new THREEx.ArMarkerControls(arToolkitContext, camera, {
		type : 'pattern',
		patternUrl : 'data/patt.hiro',
		// patternUrl : THREEx.ArToolkitContext.baseURL + '../data/data/patt.kanji',
		// as we controls the camera, set changeMatrixMode: 'cameraTransformMatrix'
		changeMatrixMode: 'cameraTransformMatrix'
	})
	// as we do changeMatrixMode: 'cameraTransformMatrix', start with invisible scene
	scene.visible = false

	//////////////////////////////////////////////////////////////////////////////////
	//		add an object in the scene
	//////////////////////////////////////////////////////////////////////////////////

	
	// onRenderFcts.push(function(delta){
	// 	mesh.rotation.x += Math.PI*delta
	// })

	//////////////////////////////////////////////////////////////////////////////////
	//		render the whole thing on the page
	//////////////////////////////////////////////////////////////////////////////////

	// render the scene
	onRenderFcts.push(function(){
		renderer.render( scene, camera );
	})

	// run the rendering loop
	var lastTimeMsec= null
	requestAnimationFrame(function animate(nowMsec){
		// keep looping
		requestAnimationFrame( animate );
		// // measure time
		// lastTimeMsec	= lastTimeMsec || nowMsec-1000/60
		// var deltaMsec	= Math.min(200, nowMsec - lastTimeMsec)
		// lastTimeMsec	= nowMsec
		// call each update function

		// if ( mixers!=null && mixers.length > 0 ) {
		// 	for ( var i = 0; i < mixers.length; i ++ ) {
		// 		mixers[ i ].update( clock.getDelta() );
		// 	}
		// }
		onRenderFcts.forEach(function(onRenderFct){
			onRenderFct()
		})
	})

// TEST
// add a torus knot	
	var geometry	= new THREE.CubeGeometry(1,1,1);
	var material	= new THREE.MeshNormalMaterial({
		transparent : true,
		opacity: 0.5,
		side: THREE.DoubleSide
	}); 
	var mesh	= new THREE.Mesh( geometry, material );
	mesh.position.y	= geometry.parameters.height/2
	scene.add( mesh );
	
	var geometry	= new THREE.TorusKnotGeometry(0.3,0.1,64,16);
	var material	= new THREE.MeshNormalMaterial(); 
	var mesh	= new THREE.Mesh( geometry, material );
	mesh.position.y	= 0.5
	scene.add( mesh );
	
	onRenderFcts.push(function(delta){
		mesh.rotation.x += Math.PI*delta
	})

//-----------
	// model
	// var mixers = [];
	// var clock = new THREE.Clock();

	// var manager = new THREE.LoadingManager();
	// manager.onProgress = function( item, loaded, total ) {
	// 	console.log( item, loaded, total );
	// };
	// var onProgress = function( xhr ) {
	// 	if ( xhr.lengthComputable ) {
	// 		var percentComplete = xhr.loaded / xhr.total * 100;
	// 		console.log( Math.round( percentComplete, 2 ) + '% downloaded' );
	// 	}
	// };
	// var onError = function( xhr ) {
	// 	console.error( xhr );
	// };
	// var loader = new THREE.FBXLoader( manager );
	// loader.load( 'models/xsi_man_skinning.fbx', function( object ) {
	// 	object.scale.set(0.02, 0.02, 0.02);
	// 	object.rotation.set(-Math.PI/2, 0, 0);

	// 	object.mixer = new THREE.AnimationMixer( object );
	// 	mixers.push( object.mixer );
	// 	if(object.animations.length > 0 ) {
	// 		var action = object.mixer.clipAction( object.animations[ 0 ] );
	// 		action.play();
	// 	}

	// 	scene.add( object );
	// }, onProgress, onError );

	renderer.domElement.addEventListener("click", takeSnapshot);
	var download_photo_btn = document.querySelector('#download-photo');
    function takeSnapshot() {
        // Here we're using a trick that involves a hidden canvas element.
        var hidden_canvas = document.querySelector('canvas'),
                context = hidden_canvas.getContext('2d');

        var width = arToolkitSource.domElement.videoWidth,
                height = arToolkitSource.domElement.videoHeight;

        if (width && height) {
            // Setup a canvas with the same dimensions as the video.
            hidden_canvas.width = width;
            hidden_canvas.height = height;
            // Make a copy of the current frame in the video on the canvas.
            context.drawImage(arToolkitSource.domElement, 0, 0, width, height);
            context.drawImage(renderer.domElement, 0, 0, width, height);
            // Turn the canvas image into a dataURL that can be used as a src for our photo.
            download_photo_btn.href = hidden_canvas.toDataURL('image/png');
            download_photo_btn.click();
           context.clearRect(0, 0, hidden_canvas.width, hidden_canvas.height);
        }
    }
</script>

</body>
